{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c640ef-9320-4f4f-bb85-255326133ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VS2Net_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2add936-a65c-414d-ac07-9c9fd0b45915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f855a-344b-406a-adff-309ae1512937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.special import wofz\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import trange\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a452a6a-9ec2-40e8-b1a5-a6da9a24323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(x, permitted_list):\n",
    "    \"\"\"\n",
    "    Maps input elements x which are not in the permitted list to the last element\n",
    "    of the permitted list.\n",
    "    \"\"\"\n",
    "\n",
    "    if x not in permitted_list:\n",
    "        x = permitted_list[-1]\n",
    "\n",
    "    binary_encoding = [int(boolean_value) for boolean_value in list(map(lambda s: x == s, permitted_list))]\n",
    "\n",
    "    return binary_encoding\n",
    "def get_atom_features(atom,\n",
    "                      use_chirality = True,\n",
    "                      hydrogens_implicit = True):\n",
    "    #输入rdkit atom，输出1d numpy array\n",
    "    permitted_list_of_atoms =  ['C','N','O','S','F','P','Cl','Br','Unknown']\n",
    "    if hydrogens_implicit == False:\n",
    "        permitted_list_of_atoms = ['H'] + permitted_list_of_atoms\n",
    "        \n",
    "    atom_type_enc = one_hot_encoding(str(atom.GetSymbol()),permitted_list_of_atoms)\n",
    "    n_heavy_neighbors_enc = one_hot_encoding(int(atom.GetDegree()), [0, 1, 2, 3, 4, \"MoreThanFour\"])\n",
    "    formal_charge_enc = one_hot_encoding(int(atom.GetFormalCharge()), [-3, -2, -1, 0, 1, 2, 3, \"Extreme\"])\n",
    "    hybridisation_type_enc = one_hot_encoding(str(atom.GetHybridization()), [\"S\", \"SP\", \"SP2\", \"SP3\", \"SP3D\", \"SP3D2\", \"OTHER\"])\n",
    "    is_in_a_ring_enc = [int(atom.IsInRing())]\n",
    "    is_aromatic_enc = [int(atom.GetIsAromatic())]\n",
    "    atomic_mass_scaled = [float((atom.GetMass() - 10.812)/116.092)]\n",
    "    vdw_radius_scaled = [float((Chem.GetPeriodicTable().GetRvdw(atom.GetAtomicNum()) - 1.5)/0.6)]\n",
    "    covalent_radius_scaled = [float((Chem.GetPeriodicTable().GetRcovalent(atom.GetAtomicNum()) - 0.64)/0.76)]\n",
    "    \n",
    "    atom_feature_vector = atom_type_enc + n_heavy_neighbors_enc + formal_charge_enc + hybridisation_type_enc + is_in_a_ring_enc + is_aromatic_enc + atomic_mass_scaled + vdw_radius_scaled + covalent_radius_scaled\n",
    "    \n",
    "    if use_chirality == True:\n",
    "        chirality_type_enc = one_hot_encoding(str(atom.GetChiralTag()), [\"CHI_UNSPECIFIED\", \"CHI_TETRAHEDRAL_CW\", \"CHI_TETRAHEDRAL_CCW\", \"CHI_OTHER\"])\n",
    "        atom_feature_vector += chirality_type_enc\n",
    "    if hydrogens_implicit == True:\n",
    "        n_hydrogens_enc = one_hot_encoding(int(atom.GetTotalNumHs()), [0, 1, 2, 3, 4, \"MoreThanFour\"])\n",
    "        atom_feature_vector += n_hydrogens_enc\n",
    "        \n",
    "    return np.array(atom_feature_vector)\n",
    "\n",
    "\n",
    "def get_bond_features(bond, \n",
    "                      use_stereochemistry = True):\n",
    "   #输入rdkit bond，输出1d numpy array\n",
    "\n",
    "    permitted_list_of_bond_types = [Chem.rdchem.BondType.SINGLE, Chem.rdchem.BondType.DOUBLE, Chem.rdchem.BondType.TRIPLE, Chem.rdchem.BondType.AROMATIC]\n",
    "\n",
    "    bond_type_enc = one_hot_encoding(bond.GetBondType(), permitted_list_of_bond_types)    \n",
    "    bond_is_conj_enc = [int(bond.GetIsConjugated())]    \n",
    "    bond_is_in_ring_enc = [int(bond.IsInRing())]  \n",
    "    \n",
    "    bond_feature_vector = bond_type_enc + bond_is_conj_enc + bond_is_in_ring_enc\n",
    "    \n",
    "    if use_stereochemistry == True:\n",
    "        stereo_type_enc = one_hot_encoding(str(bond.GetStereo()), [\"STEREOZ\", \"STEREOE\", \"STEREOANY\", \"STEREONONE\"])\n",
    "        bond_feature_vector += stereo_type_enc\n",
    "\n",
    "    return np.array(bond_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bfc79c-90a8-4195-9594-759a551b0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target,mode = extract_labels(all_files[i])\n",
    "\n",
    "def get_feature_and_labels(ii,target,mode):\n",
    "    #对于x---输入图（atom数*45维）edges_index(2*键数)edge_attr(键数*10)\n",
    "    #对于y---输出nparray50维\n",
    "    smi = data.iloc[ii][0]\n",
    "    mol = Chem.MolFromSmiles(data.iloc[ii][0])\n",
    "    target = target\n",
    "    mode = mode\n",
    "\n",
    "    n_nodes = mol.GetNumAtoms()\n",
    "    n_edges = 2*mol.GetNumBonds()\n",
    "    X =np.zeros((n_nodes,45))\n",
    "    \n",
    "    for atom in mol.GetAtoms():\n",
    "        X[atom.GetIdx(),:] = get_atom_features(atom)\n",
    "    X = torch.tensor(X,dtype = torch.float)\n",
    "\n",
    "    # construct edge index array E of shape (2, n_edges)\n",
    "    (rows, cols) = np.nonzero(GetAdjacencyMatrix(mol))\n",
    "    torch_rows = torch.from_numpy(rows.astype(np.int64)).to(torch.long)\n",
    "    torch_cols = torch.from_numpy(cols.astype(np.int64)).to(torch.long)\n",
    "    E = torch.stack([torch_rows, torch_cols], dim = 0)\n",
    "    \n",
    "    # construct edge feature array EF of shape (n_edges, n_edge_features)\n",
    "    EF = np.zeros((n_edges, 10))        \n",
    "    for (k, (m,j)) in enumerate(zip(rows, cols)):\n",
    "        EF[k] = get_bond_features(mol.GetBondBetweenAtoms(int(m),int(j)))        \n",
    "    EF = torch.tensor(EF, dtype = torch.float)\n",
    "    \n",
    "    #y_tensor = torch.tensor(y_50_tran(i))\n",
    "    return Data(x=X,edge_index=E,edge_attr=EF,target = target,mode=mode,smi=smi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59f8a1b-40be-4040-95d0-d1d019b883c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "root_dir = \"/home/chengc/workspace/cc/data/dude/dude_smi\"\n",
    "for dirpath, dirnames, files in os.walk(root_dir):  \n",
    "    for name in files:  \n",
    "        all_files.append(os.path.join(dirpath, name)) \n",
    "def extract_labels(file_path):  \n",
    "    # 分割文件名和目录部分  \n",
    "    filename = os.path.basename(file_path)  \n",
    "    # 去掉文件扩展名  \n",
    "    filename_without_ext = os.path.splitext(filename)[0]  \n",
    "    # 分割文件名以获得前缀和标签  \n",
    "    parts = filename_without_ext.split('_')  \n",
    "    # 假设前缀和标签分别位于倒数第二和最后一个位置  \n",
    "    target_protein = parts[-4] if len(parts) > 1 else None  \n",
    "    mode = parts[-3] if len(parts) > 0 else None  \n",
    "    # 返回前缀和标签  \n",
    "    return target_protein, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f9dfc-9f0d-43e5-b244-f93f7d2ee77d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in trange(len(all_files)):\n",
    "    target,mode = extract_labels(all_files[i])\n",
    "    data = pd.read_csv(all_files[i])\n",
    "    data_all = []\n",
    "    save_dir = os.path.join(\"/home/chengc/workspace/cc/0815/data/cal_data/dude_graph\",target+\"_\"+mode+\".pt\")\n",
    "    for ii in range(len(data)):\n",
    "        point = get_feature_and_labels(ii,target,mode)\n",
    "        data_all.append(point)\n",
    "    torch.save(data_all,save_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93dd2ac-dc73-48ce-8247-81e5f5901521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff8529-d26c-4b6b-b546-915aafe06bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv,EdgeConv\n",
    "from torch_geometric.nn import global_mean_pool,global_max_pool\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eccdfe4-9683-42c8-a8b7-da453075a37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###模型导入\n",
    "class GNN_COS(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(42)\n",
    "       \n",
    "        self.conv1 = GCNConv(45, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels,hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels,hidden_channels)\n",
    "        self.conv4 = GCNConv(hidden_channels,hidden_channels)\n",
    "        self.conv5 = GCNConv(hidden_channels,hidden_channels)\n",
    "        \n",
    "        self.lin1 = nn.Linear(2*hidden_channels,hidden_channels)\n",
    "        self.lin2 = nn.Linear(hidden_channels,hidden_channels)\n",
    "        self.out = nn.Linear(hidden_channels, 50)\n",
    "        \n",
    "        self.loss_function1 = nn.CosineEmbeddingLoss(margin=0)\n",
    "        self.loss_function2 = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0001, weight_decay=5e-4)\n",
    "        self.counter=0\n",
    "        self.progress = []\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        \n",
    "        x = x.to(device)\n",
    "        edge_index = edge_index.to(device)\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        x=self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x=self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x=self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x=self.conv4(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x=self.conv5(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = torch.cat((global_mean_pool(x,batch),global_max_pool(x,batch)),dim=1)\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "        x = x.relu()\n",
    "        out = self.out(x)\n",
    "        return out\n",
    "    \n",
    "    def train(self,data):\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        outputs = self.forward(data.x.float(),data.edge_index,data.batch)\n",
    "        y = data.y.to(device)\n",
    "        batch_size = data.batch_size\n",
    "        target = torch.ones(batch_size)\n",
    "        target = target.to(device)\n",
    "        #loss = cos_ratio*self.loss_function1(outputs.to(torch.float32),y.view(batch_size,50).to(torch.float32),target)+mse_ratio*self.loss_function2(outputs.to(torch.float32),y.view(batch_size,50).to(torch.float32))\n",
    "        loss = self.loss_function1(outputs.to(torch.float32),y.view(batch_size,50).to(torch.float32),target)\n",
    "        self.progress.append(loss.item())        \n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    #def test(self,data):\n",
    "        #outputs = self.forward(data.x.float(),data.edge_index,data.batch)\n",
    "        #target = torch.ones(len(data))\n",
    "        #target = target.to(device)\n",
    "        #y = data.y.to(device)\n",
    "        #acc = cos_ratio*self.loss_function1(outputs.to(torch.float32),y.view(len(test_data),50).to(torch.float32),target)+mse_ratio*self.loss_function2(outputs.to(torch.float32),y.view(len(test_data),50).to(torch.float32))\n",
    "        #acc = self.loss_function1(outputs.to(torch.float32),y.view(len(data),50).to(torch.float32),target)\n",
    "        #return acc\n",
    "    \n",
    "    def pred(self,data):\n",
    "        outputs = self.forward(data.x.float(),data.edge_index,data.batch)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "\n",
    "class GNN_MSE(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(42)\n",
    "       \n",
    "        self.conv1 = GCNConv(45, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels,hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels,hidden_channels)\n",
    "        self.conv4 = GCNConv(hidden_channels,hidden_channels)\n",
    "        self.conv5 = GCNConv(hidden_channels,hidden_channels)\n",
    "        \n",
    "        self.lin1 = nn.Linear(2*hidden_channels,hidden_channels)\n",
    "        self.lin2 = nn.Linear(hidden_channels,hidden_channels)\n",
    "        self.out = nn.Linear(hidden_channels, 50)\n",
    "        \n",
    "        self.loss_function1 = nn.CosineEmbeddingLoss(margin=0)\n",
    "        self.loss_function2 = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0001, weight_decay=5e-4)\n",
    "        self.counter=0\n",
    "        self.progress = []\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        \n",
    "        x = x.to(device)\n",
    "        edge_index = edge_index.to(device)\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        x=self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x=self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x=self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x=self.conv4(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x=self.conv5(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = torch.cat((global_mean_pool(x,batch),global_max_pool(x,batch)),dim=1)\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "        x = x.relu()\n",
    "        out = self.out(x)\n",
    "        return out\n",
    "    \n",
    "    def train(self,data):\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        outputs = self.forward(data.x.float(),data.edge_index,data.batch)\n",
    "        y = data.y.to(device)\n",
    "        batch_size = data.batch_size\n",
    "        target = torch.ones(batch_size)\n",
    "        target = target.to(device)\n",
    "        #loss = cos_ratio*self.loss_function1(outputs.to(torch.float32),y.view(batch_size,50).to(torch.float32),target)+mse_ratio*self.loss_function2(outputs.to(torch.float32),y.view(batch_size,50).to(torch.float32))\n",
    "        loss = self.loss_function2(outputs.to(torch.float32),y.view(batch_size,50).to(torch.float32))\n",
    "        self.progress.append(loss.item())        \n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    #def test(self,data):\n",
    "        #outputs = self.forward(data.x.float(),data.edge_index,data.batch)\n",
    "        #target = torch.ones(len(test_data))\n",
    "        #target = target.to(device)\n",
    "        #y = data.y.to(device)\n",
    "        #acc = cos_ratio*self.loss_function1(outputs.to(torch.float32),y.view(len(test_data),50).to(torch.float32),target)+mse_ratio*self.loss_function2(outputs.to(torch.float32),y.view(len(test_data),50).to(torch.float32))\n",
    "        #acc = self.loss_function2(outputs.to(torch.float32),y.view(batch_size,50).to(torch.float32))\n",
    "        #return acc\n",
    "    \n",
    "    def pred(self,data):\n",
    "        outputs = self.forward(data.x.float(),data.edge_index,data.batch)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "hidden_channels=512\n",
    "model_cos = GNN_COS()\n",
    "model_mse = GNN_MSE()\n",
    "\n",
    "model_mse.load_state_dict(torch.load(\"/home/chengc/workspace/cc/0815/model/qm_9_mse_model.pth\"))\n",
    "model_cos.load_state_dict(torch.load(\"/home/chengc/workspace/cc/0815/model/qm_9_cos_model.pth\"))\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model_mse.to(device)\n",
    "model_cos.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec21e4-5cfd-4e72-a4da-414a0d7e7f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "root_dir = \"/home/chengc/workspace/cc/0815/data/cal_data/dude_graph\"\n",
    "for dirpath, dirnames, files in os.walk(root_dir):  \n",
    "    for name in files:  \n",
    "        all_files.append(os.path.join(dirpath, name)) \n",
    "def extract_labels(file_path):  \n",
    "    # 分割文件名和目录部分  \n",
    "    filename = os.path.basename(file_path)  \n",
    "    # 去掉文件扩展名  \n",
    "    filename_without_ext = os.path.splitext(filename)[0]  \n",
    "    # 分割文件名以获得前缀和标签  \n",
    "    parts = filename_without_ext.split('_')  \n",
    "    # 假设前缀和标签分别位于倒数第二和最后一个位置  \n",
    "    target_protein = parts[-2] if len(parts) > 1 else None  \n",
    "    mode = parts[-1] if len(parts) > 0 else None  \n",
    "    # 返回前缀和标签  \n",
    "    return target_protein, mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119af18d-4c7c-469b-b4f0-a89625c96a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in trange(len(all_files)):\n",
    "    data = torch.load(all_files[n])\n",
    "    data_loader = DataLoader(data,batch_size=1)\n",
    "    input_data = []\n",
    "    for loader in data_loader:\n",
    "        input_data.append(loader)\n",
    "    mse_predict = []\n",
    "    for ii in range(len(input_data)):\n",
    "        mse_predict.append(model_mse.pred(input_data[ii])[0].detach())\n",
    "    \n",
    "    cos_predict = []\n",
    "    for iii in range(len(input_data)):\n",
    "        cos_predict.append(model_cos.pred(input_data[iii])[0].detach())\n",
    "    \n",
    "    def datatran(m):\n",
    "        mse_spec = mse_predict[m]\n",
    "        cos_spec = cos_predict[m]*10000\n",
    "        x100 = mse_spec.tolist()+cos_spec.tolist()\n",
    "        x100 = torch.tensor(x100)\n",
    "        receptor = input_data[m].target[0]\n",
    "        smi = input_data[m].smi[0]\n",
    "        mode = input_data[m].mode[0]\n",
    "        if mode == \"actives\":\n",
    "            y_c = torch.tensor(1)\n",
    "        else : y_c =torch.tensor(0)\n",
    "        return Data(x=x100,y=y_c,receptor=receptor,smi=smi)\n",
    "    \n",
    "    data100 = []\n",
    "    targets,modes = extract_labels(all_files[n])\n",
    "    save_dir = os.path.join(\"/home/chengc/workspace/cc/0815/data/cal_data/dude_spec_step1\",targets+\"_\"+modes+\".pt\")\n",
    "    for iiii in range(len(input_data)):\n",
    "        point = datatran(iiii)\n",
    "        data100.append(point)\n",
    "    torch.save(data100,save_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a2440-3e98-4773-9190-e6e23dc2897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step3 2in1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1ba96d-21f8-44b8-819b-ca5b1389aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import trange\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0363c999-95e0-4951-a649-c74f55d8602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###load the model\n",
    "hidden_channels = 256\n",
    "class twoinone(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(42)\n",
    "       \n",
    "        self.nn1 = nn.Linear(100, hidden_channels*2)\n",
    "        self.nn2 = nn.Linear(hidden_channels*2,hidden_channels*2)\n",
    "        self.nn3 = nn.Linear(hidden_channels*2,hidden_channels*2)\n",
    "        self.nn4 = nn.Linear(hidden_channels*2,hidden_channels*2)\n",
    "        self.out = nn.Linear(hidden_channels*2, 50)\n",
    "        \n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0001, weight_decay=5e-4)\n",
    "        self.counter=0\n",
    "        self.progress = []\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = x.to(device)\n",
    "        x=self.nn1(x)\n",
    "        x = x.relu()\n",
    "        x=self.nn2(x)\n",
    "        x = x.relu()\n",
    "        x=self.nn3(x)\n",
    "        x = x.relu()\n",
    "        x=self.nn4(x)\n",
    "        x = x.relu()\n",
    "        out = self.out(x)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def train(self,data):\n",
    "        loss_batch=[]\n",
    "        for i in range(data.batch_size):            \n",
    "            outputs = self.forward(data[i].x.float())\n",
    "            y = data[i].y.to(device)\n",
    "            y = y.float()\n",
    "            loss_part = self.loss_function(outputs.to(torch.float32),y.to(torch.float32))\n",
    "            loss_batch.append(loss_part)\n",
    "        loss = torch.stack(loss_batch,dim=0).mean(dim=0)           \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss\n",
    "    \n",
    "    def val(self,data):\n",
    "        vloss_batch=[]\n",
    "        for i in range(data.batch_size):            \n",
    "            outputs = self.forward(data[i].x.float())\n",
    "            y = data[i].y.to(device)\n",
    "            y = y.float()\n",
    "            loss_part = self.loss_function(outputs.to(torch.float32),y.to(torch.float32))\n",
    "            vloss_batch.append(loss_part)\n",
    "        loss = torch.stack(vloss_batch,dim=0).mean(dim=0) \n",
    "        return loss\n",
    "    \n",
    "    def pred(self,data):\n",
    "        output = self.forward(data.x)\n",
    "        return output\n",
    "    \n",
    "device = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')\n",
    "model = twoinone()\n",
    "model.load_state_dict(torch.load(\"/home/chengc/workspace/cc/0815/model/qm_9_2in1_model.pth\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eab7abd-b6b9-4397-b4d1-c627714e74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "root_dir = \"/home/chengc/workspace/cc/0815/data/cal_data/dude_spec_step1\"\n",
    "for dirpath, dirnames, files in os.walk(root_dir):  \n",
    "    for name in files:  \n",
    "        all_files.append(os.path.join(dirpath, name)) \n",
    "def extract_labels(file_path):  \n",
    "    # 分割文件名和目录部分  \n",
    "    filename = os.path.basename(file_path)  \n",
    "    # 去掉文件扩展名  \n",
    "    filename_without_ext = os.path.splitext(filename)[0]  \n",
    "    # 分割文件名以获得前缀和标签  \n",
    "    parts = filename_without_ext.split('_')  \n",
    "    # 假设前缀和标签分别位于倒数第二和最后一个位置  \n",
    "    target_protein = parts[-2] if len(parts) > 1 else None  \n",
    "    mode = parts[-1] if len(parts) > 0 else None  \n",
    "    # 返回前缀和标签  \n",
    "    return target_protein, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f799bb4b-ca19-4693-b23c-869b581533df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in trange(len(all_files)):\n",
    "    data = torch.load(all_files[i])\n",
    "    targets,modes = extract_labels(all_files[i])\n",
    "    save_dir = os.path.join(\"/home/chengc/workspace/cc/0815/data/cal_data/dude_spec_step2\",targets+\"_\"+modes+\".pt\")\n",
    "    for ii in trange(len(data)):\n",
    "        data[ii].x = torch.tensor(model.pred(data[ii]).detach().tolist(),dtype = torch.float)\n",
    "    torch.save(data,save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebfe924-330d-48a9-acd6-6663e997881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###step4 +protein_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d4fb10-ef31-42dd-9657-c50552092222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import trange\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57499a28-c07c-4b1b-aade-fadca351016d",
   "metadata": {},
   "source": [
    "#protein_max = 3.7739898962011713\n",
    "#mol_max = 91.85801696777344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a1c99-0131-4328-a3d3-6691870d7380",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_dir = \"/home/chengc/workspace/cc/data/protein/dude\"\n",
    "def get_ir(receptor):\n",
    "    ir_path = os.path.join(pro_dir,receptor+\"_addelements_sig-IR-ML.txt\")\n",
    "    freq,ir = np.loadtxt(ir_path,usecols=(0,1), unpack=True)\n",
    "    pro_y=[]\n",
    "    for i in range(0,200,4):\n",
    "        scale = max(ir)\n",
    "        sub_sum = (sum(ir[i:i+4]) / scale) * 24\n",
    "        pro_y.append(sub_sum)\n",
    "    return pro_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba3a532-2b9f-4210-a9a4-0670690910fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pro_82 = []\n",
    "for dirpath, dirnames, files in os.walk('/home/chengc/workspace/cc/data/protein/dude'):  \n",
    "    for name in files:  \n",
    "        parts = name.split('_')\n",
    "        pro_82.append(parts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f1b8ec-59c5-43b7-9946-560cf7ac18af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "root_dir = \"/home/chengc/workspace/cc/data/dude/dude_spec_step2\"\n",
    "for dirpath, dirnames, files in os.walk(root_dir):  \n",
    "    for name in files:  \n",
    "        all_files.append(os.path.join(dirpath, name)) \n",
    "def extract_labels(file_path):  \n",
    "    filename = os.path.basename(file_path)  \n",
    "    filename_without_ext = os.path.splitext(filename)[0]  \n",
    "    parts = filename_without_ext.split('_')  \n",
    "    target_protein = parts[-2] if len(parts) > 1 else None  \n",
    "    mode = parts[-1] if len(parts) > 0 else None   \n",
    "    return target_protein, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f06086-cbe9-435a-b81d-25d22f40f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trange(len(pro_82)):\n",
    "    target = pro_82[i]\n",
    "    a_data = torch.load(os.path.join(\"/home/chengc/workspace/cc/data/dude/dude_spec_step2\",target+\"_actives.pt\"))\n",
    "    d_data = torch.load(os.path.join(\"/home/chengc/workspace/cc/data/dude/dude_spec_step2\",target+\"_decoys.pt\"))\n",
    "    save_dir_a = os.path.join(\"/home/chengc/workspace/cc/0815/data/cal_data/dude_spec_withpro\",target+\"_actives.pt\")\n",
    "    save_dir_d = os.path.join(\"/home/chengc/workspace/cc/0815/data/cal_data/dude_spec_withpro\",target+\"_decoys.pt\")\n",
    "    pro_spec = get_ir(target)\n",
    "    for point in a_data:\n",
    "        point.x = torch.tensor(point.x.tolist()+pro_spec,dtype = torch.float)\n",
    "    torch.save(a_data,save_dir_a)\n",
    "    \n",
    "    for dpoint in d_data:\n",
    "        dpoint.x = torch.tensor(dpoint.x.tolist()+pro_spec,dtype = torch.float)\n",
    "    torch.save(d_data,save_dir_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbf66ce-8b91-47e2-888f-f355a836d93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1426207b-3467-4aaa-8b5e-806b0405732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step5 -> train/val/test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc94ab04-f62c-4e8e-9006-f49c4cdca793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.15s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 81/81 [03:48<00:00,  2.82s/it]\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/home/chengc/workspace/cc/0815/data/cal_data/dude_spec_withpro\"\n",
    "for i in trange(0,1):\n",
    "    a_data = torch.load(os.path.join(root_dir,pro_82[i]+\"_actives.pt\"))\n",
    "    d_data = torch.load(os.path.join(root_dir,pro_82[i]+\"_decoys.pt\"))\n",
    "    atrain_num = int(len(a_data)*0.75)\n",
    "    aval_num = int(len(a_data)*0.15)\n",
    "    atest_num = len(a_data) - atrain_num - aval_num\n",
    "    dtrain_num = atrain_num*10\n",
    "    dval_num = aval_num*10\n",
    "    dtest_num = len(d_data) - dtrain_num - dval_num               \n",
    "    atrain,aval,atest = random_split(dataset = a_data,lengths = [atrain_num,aval_num,atest_num],generator = torch.Generator().manual_seed(42))\n",
    "    dtrain,dval,dtest = random_split(dataset = d_data,lengths = [dtrain_num,dval_num,dtest_num],generator = torch.Generator().manual_seed(42))\n",
    "    train_data = atrain+dtrain\n",
    "    val_data = aval+dval\n",
    "    test_data = atest+dtest\n",
    "    \n",
    "for i in trange(1,len(pro_82)):\n",
    "    a_data = torch.load(os.path.join(root_dir,pro_82[i]+\"_actives.pt\"))\n",
    "    d_data = torch.load(os.path.join(root_dir,pro_82[i]+\"_decoys.pt\"))\n",
    "    atrain_num = int(len(a_data)*0.75)\n",
    "    aval_num = int(len(a_data)*0.15)\n",
    "    atest_num = len(a_data) - atrain_num - aval_num\n",
    "    dtrain_num = atrain_num*10\n",
    "    dval_num = aval_num*10\n",
    "    dtest_num = len(d_data) - dtrain_num - dval_num               \n",
    "    atrain,aval,atest = random_split(dataset = a_data,lengths = [atrain_num,aval_num,atest_num],generator = torch.Generator().manual_seed(42))\n",
    "    dtrain,dval,dtest = random_split(dataset = d_data,lengths = [dtrain_num,dval_num,dtest_num],generator = torch.Generator().manual_seed(42))\n",
    "    train_data = train_data+atrain+dtrain\n",
    "    val_data = val_data+aval+dval\n",
    "    test_data = test_data+atest+dtest\n",
    "torch.save(train_data,'/home/chengc/workspace/cc/0815/data/cal_data/dude_82/train_data.pt')\n",
    "torch.save(val_data,'/home/chengc/workspace/cc/0815/data/cal_data/dude_82/val_data.pt')\n",
    "torch.save(test_data,'/home/chengc/workspace/cc/0815/data/cal_data/dude_82/test_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13475cc9-c8ec-4664-9d22-211e277f6038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
